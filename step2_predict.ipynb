{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "You should prepare the following before running this step. Please refer to the `example_data/data` folder for guidance:\n",
    "\n",
    "1. **image data**\n",
    "   - you want to prepare the SAX data as a 4D array [x,y,time_frame,slice_num] saved as a nii file. in our study we sample 15 time frames as default. please refer ```example_data/data/ID_0002``` as SAX reference  \n",
    "   - you want to prepare the LAX data as a 3D array [x,y,time_frame]. please refer ```example_data/data/ID_0085``` as SAX reference  \n",
    "\n",
    "2. **A patient list** that enumerates all your cases\n",
    "   - To understand the standard format, please refer to the file:  \n",
    "     `example_data/Patient_list/patient_list.xlsx`\n",
    "   - make sure column ***total_slice_num*** is correct for each case\n",
    "\n",
    "4. **Text prompts** that specifies the view type\n",
    "   - our model takes text prompt \"SAX\" or \"LAX\" to specify the view type \n",
    "   - we use \"CLIP\" model to embed text prompts (code: ```dataset/CMR/clip_extractor.ipynb```)\n",
    "   - we have prepared the embedded feature in `example_data/data/text_prompt_clip`, please download to your local\n",
    "\n",
    "5. **Box prompts** that indicates the location of myocardium\n",
    "   - in the prediction you need to define box prompts manually by yourself if you want to use this feature\n",
    "   - we prepare examplar bounding box ```example_data/data/ID_0002/bounding_box.npy``` which saves the bounding box as a 4D array [f,s,2,4] where f is the number of cases, s is the slice num in each case, 2 refers to ED and ES, 4 refers to at each frame the definition of [xmin, ymin, xmax, ymax] of the bounding box. \n",
    "   - If you don't define the box, the model will just pass None as box prompt. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Docker environment\n",
    "Please use `docker`, it will build a pytorch-based container\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 338M/338M [00:02<00:00, 128MiB/s]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append('/workspace/Documents')  ### remove this if not needed!\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import torch.backends.cudnn as cudnn\n",
    " \n",
    "from cineCMR_SAM.utils.model_util import *\n",
    "from cineCMR_SAM.segment_anything.model import build_model \n",
    "from cineCMR_SAM.utils.save_utils import *\n",
    "from cineCMR_SAM.utils.config_util import Config\n",
    "\n",
    "import cineCMR_SAM.inference_engine as inference_engine\n",
    "\n",
    "import cineCMR_SAM.dataset.build_CMR_datasets as build_CMR_datasets\n",
    "import cineCMR_SAM.functions_collection as ff\n",
    "import cineCMR_SAM.get_args_parser as get_args_parser\n",
    "\n",
    "main_path = '/mnt/camca_NAS/SAM_for_CMR/'  # replace with your own path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define parameters for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set experiment-specific parameters\n",
    "trial_name = 'cineCMR_sam_trial' \n",
    "\n",
    "output_dir = os.path.join(main_path, 'example_data/models', trial_name)\n",
    "ff.make_folder([os.path.join(main_path, 'example_data/models'), output_dir])\n",
    "\n",
    "text_prompt = True # whether we need to input text prompt to specify the view types (LAX or SAX). True or False. default = True\n",
    "box_prompt = False # whether we have the bounding box for myocardium defined by the user. False means no box, 'one' means one box at ED and 'two' means two boxes at ED and ES\n",
    "\n",
    "# define trained model\n",
    "pretrained_model = os.path.join(main_path, 'example_data/models',trial_name,'models/model-sax.pth')  # replace with your own path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# default\n",
    "# preload the text prompt feature \n",
    "sax_text_prompt_feature = np.load(os.path.join(main_path,'example_data/data/text_prompt_clip/sax.npy'))\n",
    "lax_text_prompt_feature = np.load(os.path.join(main_path,'example_data/data/text_prompt_clip/lax.npy'))\n",
    "\n",
    "# define the original SAM model\n",
    "original_sam = os.path.join( main_path, 'example_data/pretrained_sam/sam_vit_h_4b8939.pth') \n",
    "\n",
    "args = get_args_parser.get_args_parser(text_prompt = text_prompt, \n",
    "                                       box_prompt = box_prompt, \n",
    "                                       pretrained_model = pretrained_model, \n",
    "                                       original_sam = original_sam, )\n",
    "args = args.parse_args([])\n",
    "\n",
    "# some other settings\n",
    "cfg = Config(args.config)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sax_or_lax = 'sax'\n",
    "save_folder_name = 'predicts_'+sax_or_lax\n",
    "patient_list_file = os.path.join(main_path,'example_data/data/Patient_list/patient_list_sax.xlsx') if sax_or_lax == 'sax' else os.path.join(main_path,'example_data/data/Patient_list/patient_list_lax.xlsx')\n",
    "patient_index_list = np.arange(0,1,1)\n",
    "\n",
    "dataset_pred = build_CMR_datasets.build_dataset(\n",
    "        args,\n",
    "        view_type = sax_or_lax,\n",
    "        patient_list_file = patient_list_file, \n",
    "        index_list = patient_index_list, \n",
    "        text_prompt_feature = sax_text_prompt_feature if sax_or_lax == 'sax' else lax_text_prompt_feature,\n",
    "        only_myo = True, \n",
    "        shuffle = False, \n",
    "        augment = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1950/3991271910.py:4: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Important! text prompt: True\n",
      "Important! box prompt: True\n",
      "loading pretrained model :  /mnt/camca_NAS/SAM_for_CMR/example_data/models/cineCMR_sam_trial/models/model-62.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1950/3991271910.py:10: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  finetune_checkpoint = torch.load(args.pretrained_model)\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:01,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:01,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [00:02,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [00:03,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [00:03,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "6it [00:04,  1.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "7it [00:04,  1.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "8it [00:05,  1.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9it [00:05,  1.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:06,  1.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "patient_id:  ID_0002  slice_index:  10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:07,  1.56it/s]\n"
     ]
    }
   ],
   "source": [
    "data_loader_pred = torch.utils.data.DataLoader(dataset_pred, batch_size = 1, shuffle = False, pin_memory = True, num_workers = 0)\n",
    "\n",
    "with torch.no_grad():\n",
    "    with torch.cuda.amp.autocast():\n",
    "        model = build_model(args, device)#skip_nameing = True, chunk = np.shape(np.zeros(0)))\n",
    "\n",
    "        # load the pretrained model\n",
    "        if args.pretrained_model is not None:\n",
    "            print('loading pretrained model : ', args.pretrained_model)\n",
    "            finetune_checkpoint = torch.load(args.pretrained_model)\n",
    "            model.load_state_dict(finetune_checkpoint[\"model\"])\n",
    "                            \n",
    "        # do the prediction for each slice (2D+T) one by one\n",
    "        for data_iter_step, batch in tqdm(enumerate(data_loader_pred)):\n",
    "                \n",
    "            patient_id = batch[\"patient_id\"][0]\n",
    "            slice_index = batch[\"slice_index\"].item()\n",
    "            print('patient_id: ', patient_id, ' slice_index: ', slice_index)\n",
    "                \n",
    "            save_folder_patient = os.path.join(main_path, 'example_data/models',trial_name, save_folder_name, patient_id)\n",
    "            ff.make_folder([os.path.dirname(save_folder_patient), save_folder_patient])\n",
    "\n",
    "            batch[\"image\"]= batch[\"image\"].cuda()\n",
    "\n",
    "            batch[\"text_prompt_feature\"] = batch[\"text_prompt_feature\"].to(torch.float32)\n",
    "\n",
    "            bbox = batch[\"box_prompt\"].detach().cpu().numpy()[0]\n",
    "                    \n",
    "            output = model(batch, args.img_size)\n",
    "\n",
    "            torch.cuda.synchronize()\n",
    "            \n",
    "            inference_engine.save_predictions(view_type = sax_or_lax, batch = batch, output = output, args = args, save_folder_patient = save_folder_patient)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
